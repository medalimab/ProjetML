# DÃ©tection Automatique de LÃ©sions du Genou par IRM avec Deep Learning



## ğŸ“Œ Table des MatiÃ¨res
1. [Objectifs du Projet](#-objectifs-du-projet)
2. [Jeu de DonnÃ©es](#-jeu-de-donnÃ©es)
3. [PrÃ©traitement](#-prÃ©traitement)
4. [Architecture du ModÃ¨le](#-architecture-du-modÃ¨le)
5. [RÃ©sultats](#-rÃ©sultats)
6. [DÃ©ploiement](#-dÃ©ploiement)
7. [Perspectives](#-perspectives)

## ğŸ¯ Objectifs du Projet

### Contexte MÃ©dical
Les lÃ©sions ligamentaires du genou affectent des millions de patients annuellement. Ce projet vise Ã  automatiser le diagnostic Ã  partir d'IRM pour :

- **RÃ©duire le temps d'analyse** de 30 min Ã  quelques secondes
- **Standardiser les diagnostics** (variabilitÃ© inter-radiologues : Â±23%)
- **DÃ©tecter les lÃ©sions subtiles** souvent manquÃ©es

### Pathologies CiblÃ©es
- DÃ©chirures du LCA (Ligament CroisÃ© AntÃ©rieur)
- LÃ©sions mÃ©niscales
- Anomalies gÃ©nÃ©rales du genou

## ğŸ“Š Jeu de DonnÃ©es

**Source** : MRNet-v1.0 (Stanford Medicine)

| CaractÃ©ristique          | DÃ©tails                          |
|--------------------------|----------------------------------|
| Examens d'entraÃ®nement   | 1,130 IRM annotÃ©es              |
| Examens de validation    | 120 IRM                         |
| Format                   | .npy (NumPy arrays)             |
| RÃ©solution               | 256Ã—256 pixels (20-40 tranches) |
| Annotations              | Binaires (0=normal, 1=anormal)  |

**ğŸ“Š ComprÃ©hension des DonnÃ©es** :
 Structure des donnÃ©es
Images IRM au format .npy (tableaux NumPy)
Chaque IRM contient 20 Ã  40 tranches en niveaux de gris
RÃ©solution originale : 256Ã—256 pixels
 **ğŸ”¢ Annotations binaires**
Anomalie gÃ©nÃ©rale : 0 = normal, 1 = anormal
LÃ©sion du LCA : 0/1
LÃ©sion mÃ©niscale : 0/1
**ğŸ“‘ MÃ©tadonnÃ©es**
Fichiers CSV contenant :
Identifiant de lâ€™examen (0000.npy)
Label associÃ© (0 ou 1)
Fichiers : train-abnormal.csv, train-acl.csv, train-meniscus.csv
**ğŸ‘ï¸â€ğŸ—¨ï¸ AperÃ§u des donnÃ©es**
Nombre dâ€™IRM dâ€™entraÃ®nement : 1130
Exemple de forme : (20, 256, 256)
AprÃ¨s prÃ©traitement : (1130, 3, 224, 224)
## ğŸ›  PrÃ©paration des DonnÃ©es
**ğŸ§¼ PrÃ©traitement des images**
Conversion des fichiers .npy en tableaux NumPy
Normalisation des pixels (valeurs entre 0 et 1)
SÃ©lection de 3 tranches centrales par IRM
Redimensionnement Ã  224x224
Conversion au format float32
**ğŸ” Augmentation de donnÃ©es (phase d'entraÃ®nement uniquement)**
Rotation alÃ©atoire (Â±15Â°)
Zoom (90-110%)
Retournement horizontal (50 % de chance)
**ğŸ· PrÃ©paration des labels**
RÃ©plication des labels pour les 3 tranches
Conversion en one-hot encoding pour l'entraÃ®nement multi-classes
Dictionnaire {nom_fichier: label}
## ğŸ§  ModÃ©lisation
**ğŸ§¬ CNN PersonnalisÃ©**
| Couche                  | DÃ©tails                                                                 |
|-------------------------|-------------------------------------------------------------------------|
| EntrÃ©e                  | Image (224 Ã— 224 Ã— 1)                                                   |
| Conv2D                  | 32 filtres, taille 3Ã—3, activation ReLU                                 |
| MaxPooling2D            | Taille 2Ã—2                                                              |
| BatchNormalization      | -                                                                       |
| Conv2D                  | 64 filtres, taille 3Ã—3, activation ReLU                                 |
| MaxPooling2D            | Taille 2Ã—2                                                              |
| BatchNormalization      | -                                                                       |
| Conv2D                  | 128 filtres, taille 3Ã—3, activation ReLU                                |
| MaxPooling2D            | Taille 2Ã—2                                                              |
| BatchNormalization      | -                                                                       |
| Flatten                 | Mise Ã  plat de la sortie des convolutions                              |
| Dense                   | 256 neurones, activation ReLU                                           |
| Dropout                 | Taux de dropout : 0.6                                                   |
| Dense (Sortie)          | 1 neurone, activation SigmoÃ¯de (classification binaire)                |

**RÃ©sultats**
Exactitude finale : ~82.82 %
Perte finale : ~0.4483
Temps par epoch : ~270 secondes
# 5. ğŸ§ª Ã‰valuation du ModÃ¨le
**ğŸ“Š MÃ©triques principales**
Exactitude (Accuracy) : 85.2 %
PrÃ©cision : 83.7 %
Rappel (Recall) : 86.9 %
## ğŸš€ DÃ©ploiement
Application avec Streamlit
Lâ€™application dÃ©ployÃ©e permet :
ğŸ“¤ TÃ©lÃ©versement dâ€™IRM
ğŸ¤– Analyse automatique via 3 modÃ¨les dÃ©diÃ©s :
DÃ©tection des dÃ©chirures du LCA
DÃ©tection des lÃ©sions mÃ©niscales
DÃ©tection des anomalies gÃ©nÃ©rales
ğŸ“Š Affichage des probabilitÃ©s pour chaque diagnostic

**lien de la presentation :**
https://www.canva.com/design/DAGlYnUA0vA/qSmh8j2uv9iusAls2yPYTA/edit?utm_content=DAGlYnUA0vA&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton

